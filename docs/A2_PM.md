# ДОМАШНЕЕ ЗАДАНИЕ 2. Модели предсказания

Папулин С.Ю. (papulin.study@yandex.ru)

## Цель работы

Приобрести опыт решения практических задач по машинному обучению, таких как анализ и визуализация исходных данных, обучение, выбор и оценка качества моделей предсказания, посредством языка программирования Python.

При выполнении работы решаются следующие задачи:

- реализация собственных классов совместимых с библиотекой `sklearn`
- оценка влияния регуляризации в моделях предсказания
- преобразование исходных данных посредством транформаторов `sklearn`
- использование отложенной выборки и кросс-валидации
- выбор гиперпараметров и интерпретация кривых обучения
- оценка качества моделей предсказания
- выявление преимуществ и недостатков методов предсказания в зависимости от поставленной задачи

## Вариант 

Чтобы узнать свой вариант, введите Вашу фамилию в соответствующее поле ниже и запустите ячейку:

```python
surname = "Иванов"  # Ваша фамилия

alph = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'
w = [4, 42, 21, 21, 55,  1, 44, 26, 18, 3, 38, 26, 18, 12,  3, 49, 45,
        7, 42, 9,  4,  3, 36, 33, 31, 29,  5, 4,  4, 19, 21, 27, 33]
d = dict(zip(alph, w))
variant =  sum([d[el] for el in surname.lower()]) % 40 + 1

print("Задание № 2. Вариант: ", variant % 2 + 1)
print("Задание № 3. Вариант: ", variant % 3 + 1 )
```

## Задача 1. Реализация собственных классов и функций (4 балла)

[Набор данные](../data/A2_Model_Selection/regularization.csv)

⚠️ **Замечание.** 1) Нельзя пользоваться готовыми реализациями `sklearn`; 2) чтобы избежать случая с вырожденной матрицей при оценке параметров добавьте незначительную регуляризацию по умолчанию или используйте `lstsq` из пакета `numpy` или др. способ; 3) используйте `random_state=0`

1. Реализуйте класс, предназначенный для оценки параметров линейной регрессии с регуляризацией совместимый с `sklearn`. Передаваемые параметры: 1) коэффициент регуляризации (`alpha`). Использовать метод наименьших квадратов с регуляризацией.

2. Реализуйте класс для стандартизации признаков в виде трансформации совместимый с `sklearn`. Передаваемые параметры: 1) `has_bias` (содержит ли  матрица вектор единиц), 2) `apply_mean` (производить ли центровку)

3. Реализуйте функции для расчета `MSE` и `R^2` при отложенной выборке (`run_holdout`) и кросс-валидации (`run_cross_val`). Для кросс-валидации используйте **только** класс `KFold`. Выходными значениями должны быть `MSE` и `R^2` для обучающей и тестовой частей.

    *Шаблон кода:*

    ```python
    def run_holdout(model, X, y, train_size, random_state) -> dict:
        ...
        return scores


    def run_cross_val(model, X, y, n_splits, shuffle, random_state) -> dict:
        ...
        return scores
    ```

4. Используя класс `Pipeline`, выполнить обучение линейной регрессии с предварительной стандартизацией с коэффициентом регуляризации равным `0` и `0.01`. Выведите значения параметров обученной модели. Выведите значения `MSE` и `R^2`, полученные посредством функций `run_holdout` и `run_cross_val`. Отобразите график предсказание ($\hat{y}$) - действительное значение ($y$) для разных коэффициентов регуляризации для обучающего и текстового множества. Использовать следующие параметры:
    - `train_size=0.75`, 
    - `n_splits=4`, 
    - `shuffle=True`, 
    - `random_state=0`

⚠️ **Замечание.** При формировании исходных данных использовался полином 16 степени одномерных данных. 

## Задача 2. Классификация и кросс-валидация (2 балла)

Набор данные:
- [Вариант 1](../data/A2_Model_Selection/Cl_A5_V1.csv)
- [Вариант 2](../data/A2_Model_Selection/Cl_A5_V2.csv)

⚠️ **Замечание**:
- Используйте класс логистической регрессии из `sklearn` со следующими параметрами:
    - `penalty='l2'`
    - `fit_intercept=True`
    - `max_iter=100`
    - `C=1e5`
    - `solver='liblinear'`
    - `random_state=12345`
- Разбейте исходные данные на обучающее и тестовое подмножества в соотношении `70` на `30`, `random_state=0`
- Для выбора гиперпараметров используйте два подхода: 1) с отложенной выборкой, 2) с кросс-валидацией
- Для кросс-валидации использовать функцию `cross_validate` из `sklearn`
- Параметры разбиения для выбора гиперпараметров используйте те, что в п.4 задачи 1

Дано множество наблюдений (см. набор данных к заданию), классификатор - логистическая регрессия. Найти степень полинома с минимальной ошибкой на проверочном подмножестве. Для лучшего случая рассчитать ошибку на тестовом подмножестве. В качестве метрики использовать долю правильных классификаций. Сделать заключение о влиянии степени полинома на качество предсказания.

Построить:
- диаграмму разброса исходных данных
- зависимость доли правильных классификаций от степени полинома для обучающего и проверочного подмножеств (две кривые на одном графике)
- результат классификации для наилучшего случая (степень полинома) для обучающего и тестового подмножеств с указанием границы принятия решения

## Задача 3. Классификация текстовых документов (4 балла)

- **Вариант 1.** Набор электронных сообщений (emails)
    - файл: `data/emails.tsv`
    - [источник](http://csmining.org/index.php/spam-email-datasets.html)

- **Вариант 2.** Набор SMS сообщений (sms)
    - файл: `data/SMSSpamCollection`
    - [источник](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)

- **Вариант 3.** Набор рецензий на фильмы (reviews)
    - файл: `data/reviews.tsv`
    - [источник](http://www.cs.cornell.edu/people/pabo/movie-review-data/)

1. Загрузите исходные данные
2. Разбейте исходные данные на обучающее (train, 80%) и тестовое подмножества (test, 20%)
3. Используя стратифицированную кросс-валидацию k-folds ($k=4$) для обучающего множество с метрикой `Balanced-Accuracy`, найдите лучшие гиперпараметры для следующих классификаторов:
    - K-ближайших соседей: количество соседей ($n$) из диапазона `np.arange(1, 150, 20)`
    - Логистическая регрессия: параметр регуляризации ($C$) из диапазона `np.logspace(-2, 10, 8, base=10)`
    - Наивный Байес: сглаживающий параметр модели Бернулли ($\alpha$) из диапазона `np.logspace(-4, 1, 8, base=10)`
    - Наивный Байес: сглаживающий параметр полиномиальной модели ($\alpha$) из диапазона `np.logspace(-4, 1, 8, base=10)`

4. Отобразите кривые (параметры модели)-(`Balanced-Accuracy`) при обучении и проверке для каждой классификатора (две кривые на одном графике для каждого классификатора)
5. Если необходимо, выбранные модели обучите на всём обучающем подмножестве (train) и протестируйте на тестовом (test) по `Balanced-Accuracy`, `R`, `P`, `F1`. Определите время обучения и предсказания.
6. Выполните пункты 3-5 для `n-gram=1`, `n-gram=2` и `n-gram=(1,2)`
7. Выведите в виде таблицы итоговые данные по всем методам для лучших моделей (метод, n-gram, значение параметра модели, время обучения, время предсказания, метрики (`Balanced-Accuracy`, `R`, `P`, `F1`))
8. Сделайте выводы по полученным результатам (преимущества и недостатки методов)

⚠️ **Замечание:** 
- Для всех объектов/методов/моделей `random_state = 123`
- Для выбора гиперпараметров можно использовать стандартные утилиты `sklearn`


