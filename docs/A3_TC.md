# ДОМАШНЕЕ ЗАДАНИЕ 3. Классификация текстовых документов

Папулин С.Ю. (papulin.study@yandex.ru)

## Цель работы

Приобрести опыт решения практических задач по машинному обучению, таких как анализ и визуализация исходных данных, обучение, выбор и оценка качества моделей предсказания, посредством языка программирования Python.

## Вариант 

Чтобы узнать свой вариант, введите Вашу фамилию в соответствующее поле ниже и запустите ячейку:

```python
surname = "Иванов" # Ваша фамилия

alp = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'
w = [4, 42, 21, 21, 34,  1, 44, 26, 18, 43, 38, 26, 18, 43,  3, 49, 45,
        7, 42, 25,  4,  9, 36, 33, 31, 29,  5, 31,  4, 19, 24, 27, 33]
d = dict(zip(alp, w))
variant =  sum([d[el] for el in surname.lower()]) % 3 + 1
print("Ваш вариант - ", variant)
```


- **Вариант 1.** Набор электронных сообщений (emails)
    - файл: `data/emails.tsv`
    - [источник](http://csmining.org/index.php/spam-email-datasets.html)

- **Вариант 2.** Набор SMS сообщений (sms)
    - файл: `data/SMSSpamCollection`
    - [источник](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)

- **Вариант 3.** Набор рецензий на фильмы (reviews)
    - файл: `data/reviews.tsv`
    - [источник](http://www.cs.cornell.edu/people/pabo/movie-review-data/)

⚠️ **Замечание.** 
- Для всех объектов/методов/моделей `random_state = 123`


## Задание 1. Оценка качества классификации текстовых данных (2 балла)

1. Загрузите исходные данные
2. Разбейте исходные данные на обучающее (train, 80%) и тестовое подмножества (test, 20%)
3. Переведите текстовые данные в векторный вид. Для этого воспользуйтесь средствами `sklearn` для трансформации текстовых документов в векторы TF-IDF (настроить на обучающем подмножестве, n-gram=1, слова в нижний регистр). 
4. Постройте на обучающем подмножестве следующие модели классификации:
    - K-ближайших соседей ($n=5$)
    - Логистическая регрессия ($C=1$)
    - Наивный Байес: модель Бернулли ($\alpha=1$)
    - Наивный Байес: полиномиальная модель ($\alpha=1$)
5. Определите качество классификации на тестовом подмножестве (`Balanced-Accuracy`, `R`, `P`, `F1`)
6. Определите время обучения и предсказания
7. Свести все значения в один датафрейм и представить результат в виде таблицы

⚠️ **Замечание.** 
- Для модели Бернулли используйте бинарный вектор
- Параметры логистической регрессии: `penalty="l2"`, `fit_intercept=True`, `max_iter=100`, `C=1`, `solver="lbfgs"`, `random_state=12345`

## Задание 2. Оценка качества классификации текстовых данных посредством кросс-валидации (2 балла)

Повторите решение задания 1, но с использованием стратифицированной кросс-валидации k-folds (k=4) для разделения исходных данных

## Задание 3. Выбор модели (4 балла)

1. Используя данные из задачи 1, разбейте обучающее подмножество (train) посредством стратифицированной кросс-валидации k-folds (k=4)
2. Обучите и протестируйте на разбитом обучающем подмножестве классификаторы со следующими параметрами:
    - количество соседей: `np.arange(1, 150, 20)`
    - параметр регуляризации: `np.logspace(-2, 10, 8, base=10)`
    - сглаживающий параметр: `np.logspace(-4, 1, 8, base=10)`
3. Постройте графики (параметры модели)-(`Balanced-Accuracy`) при обучении и валидации
4. Выберите лучшую модель для каждого метода, используя значение качества классификации (использовать `Balanced-Accuracy`)
5. Выбранные модели обучите на обучающем подмножестве (train) и протестируйте на тестовом (test). Определите время обучения и предсказания (см. задание 1 п. 6)
6. Повторите шаги 2-5 для n-gram=2 и n-gram=(1,2)
7. Выведите в виде таблицы итоговые данные по всем методам для лучших моделей (метод, n-gram, значение параметра модели, время обучения, время предсказания, метрики (`Balanced-Accuracy`, `R`, `P`, `F1`))
8. Сделайте выводы по полученным результатам (преимущества и недостатки методов)

## Задание 4. Оценка влияния количества признаков FeatureHasher на качество классификации (2 балла)

Как будет меняться качество классификации для обозначенных ранее методов при использовании `FeatureHasher` (или `HashingVectorizer`) из пакета `sklearn` перед TF-IDF преобразованием.

Количество признаков: `np.logspace(1, 5, 5, base=10)`

⚠️ **Замечания** 
- Используйте лучшие модели из задания 3 при `1-gram`
- Для `FeatureHasher`/`HashingVectorizer` установите следующие параметры: `norm=None` и `alternate_sign=False`


<!-- ## Задание 5. Применение ансамблевой модели

1. Создайте ансамблевый классификатор на основе моделей из задания 3 (с лучшими параметрами). В качестве итогового предсказания используйте принцип большинства
2. Оцените качество полученного классификатора (`Balanced-Accuracy`, `R`, `P`, `F1`), время обучения и время предсказания
3. Занесите полученный результат в общую таблицу из задания 3
4. Сделайте выводы относительно использования ансамблевого классификатора для вашей задачи -->