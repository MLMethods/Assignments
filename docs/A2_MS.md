# ДОМАШНЕЕ ЗАДАНИЕ 2. Выбор модели

Папулин С.Ю. (papulin.study@yandex.ru)

## Цель работы

- реализация собственных классов совместимых с библиотекой `sklearn`
- использование полиномиальной транcформации в моделях регрессии и классификации
- использование регуляризации в моделях регрессии и классификации
- выбор гиперпараметров и интерпретация кривых обучения

## Вариант 

Чтобы узнать свой вариант, введите Вашу фамилию в соответствующее поле ниже и запустите ячейку:

```python
surname = "Иванов"  # Ваша фамилия

alp = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'
w = [1, 42, 21, 21, 34,  6, 44, 26, 18, 44, 38, 26, 14, 43,  4, 49, 45,
        7, 42, 29,  4,  9, 36, 34, 31, 29,  5, 30,  4, 19, 28, 25, 33]

d = dict(zip(alp, w))
variant =  sum([d[el] for el in surname.lower()]) % 40 + 1

print("Задача № 1, шаг 5 - вариант: ", variant % 5 + 1)
print("Задача № 1, шаг 11 - вариант: ", variant % 2 + 1 )
print("задача № 2 - вариант: ", variant % 4 + 1)
```

## Задание 1. Реализация собственных классов и функций

⚠️ **Замечание.** Нельзя пользоваться готовыми реализациями `sklearn`.

1. Реализуйте класс, предназначенный для оценки параметров линейной регрессии с регуляризацией совместимый с `sklearn`. Передаваемые параметры: 1) коэффициент регуляризации (`alpha`). Использовать метод наименьших квадратов с регуляризацией.

2. Реализуйте класс для стандартизации признаков в виде трансформации совместимый с `sklearn`. Передаваемые параметры: 1) `has_bias` (содержит ли  матрица вектор единиц), 2) `apply_mean` (производить ли центровку)

3. Использую класс `Pipeline`, выполнить обучение линейной регрессии для набора данных с коэффициентом регуляризации равным `0.01`.

4. Реализуйте функции для расчета `MSE` и `R^2` при отложенной выборке (`run_holdout`) и кросс-валидации (`run_cross_val`). Для кросс-валидации используйте **только** класс `KFold`. Выходными значениями должны быть `MSE` и `R^2` для обучающей и тестовой частей.

    *Шаблон кода:*

    ```python
    def run_holdout(model, X, y, train_size, random_state) -> dict:
        ...
        return scores


    def run_cross_val(model, X, y, n_splits, shuffle, random_state) -> dict:
        ...
        return scores
    ```

4. Выведите значения `MSE` и `R^2`, полученные посредством функций `run_holdout` и `run_cross_val`. Использовать следующие параметры:
    - `train_size=0.7`, 
    - `n_splits=4`, 
    - `shuffle=True`, 
    - `random_state=0`

## Задание 2. Регрессия и кросс-валидация

[Набор данные](../data/A2_Model_Selection/Reg_A5.csv)

⚠️ **Замечание**:
- Используйте ранее реализованные классы и функции
- Разбейте исходные данные на обучающее и тестовое подмножества в соотношении 70 на 30, `random_state=0`
- Для выбора гиперпараметров используйте два подхода: 1) с отложенной выборкой, 2) с кросс-валидацией

Дано множество наблюдений (см. набор данных к заданию), модель - линейная регрессия (без регуляризации). Найти степень полинома с минимальной ошибкой на проверочном подмножестве, определить среднеквадратическую ошибку на тестовом подмножестве (степень полинома от 1 до 25).  Сделать заключение о влиянии степени полинома регуляризации.

Построить:
- диаграмму разброса исходных данных
- график зависимости среднеквадратической ошибки (`MSE`) от степени полинома для обучающего и проверочного подмножеств
- график зависимости коэффициента детерминации (`R^2`) от степени полинома для обучающего и проверочного подмножеств
- функцию регрессии (наилучший случай) + исходные данные


## Задание 3. Классификация и кросс-валидация

Набор данные:
- [Вариант 1](../data/A2_Model_Selection/Cl_A5_V1.csv)
- [Вариант 2](../data/A2_Model_Selection/Cl_A5_V2.csv)


⚠️ **Замечание**:
- Используйте класс логистической регрессии из `sklearn` со следующими параметрами:
    - `penalty='l2'`
    - `fit_intercept=True`
    - `max_iter=100`
    - `C=1e5`
    - `solver='liblinear'`
    - `random_state=12345`
- Разбейте исходные данные на обучающее и тестовое подмножества в соотношении 70 на 30, `random_state=0`
- Для выбора гиперпараметров используйте два подхода: 1) с отложенной выборкой, 2) с кросс-валидацией
- Для кросс-валидации можно использовать функцию `cross_validate` из `sklearn`

Дано множество наблюдений (см. набор данных к заданию), классификатор - логистическая регрессия. Найти степень полинома с минимальной ошибкой на проверочном подмножестве, определить долю правильных классификаций на тестовом подмножестве. Сделать заключение о влиянии степени полинома регуляризации.

Построить:
- диаграмму разброса исходных данных
- график зависимости доли правильных классификаций от степени полинома для обучающего и проверочного подмножеств
- график зависимости доли правильных классификаций от количества итераций для обучающего и проверочного подмножеств для наилучшего случая
- результат классификации для наилучшего случая (степень полинома) для обучающего и тестового подмножеств

## Задание 4. Регрессия и регуляризация

[Набор данные](../data/A2_Model_Selection/Reg_A5.csv)

Дано множество наблюдений (см. набор данных к заданию), модель - линейная регрессия c L2 регуляризацией. Найти коэффициент регуляризации с минимальной ошибкой на проверочном подмножестве, определить среднеквадратическую ошибку на тестовом подмножестве. Для выбора гиперпараметров использовать кросс-валидацию (параметры см. задание 2). Сделать заключение о влиянии коэффициента регуляризации.

```python
# Коэф. регуляризации
alphas = np.append([0.0], np.logspace(-8, 1, 20, base=10))
```
Построить:
- диаграмму разброса исходных данных
- матрицу корреляций
- график зависимости среднеквадратической ошибки от коэффициента регуляризации для обучающего и проверочного подмножеств
- график зависимости R-квадрата от коэффициента регуляризации для обучающего и проверочного подмножеств
- диаграмму разброса исходных данных вместе с графиков функции регрессии 
